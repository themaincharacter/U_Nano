{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 Wrangling OpenStreetMap Data (Chicago)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from MapZen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "import pymongo as mongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OSM file\n",
    "OSMFILE = \"chicago_city.osm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we dealing with?\n",
    "\n",
    "Lets get a list of what information we'd like to grab from the XML data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagList = []\n",
    "\n",
    "# Loop through the OSM file and store fields to a list\n",
    "def research_audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                tagList.append(tag.attrib['k'])\n",
    "    osm_file.close()\n",
    "    \n",
    "# print list as panda series with count of occurence of each field\n",
    "def printTagList():\n",
    "    pdList = pd.Series(tagList)\n",
    "    with pd.option_context('display.max_rows', 10, 'display.max_columns', 3):\n",
    "        pprint.pprint(pdList.value_counts(),compact=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building                           174484\n",
      "chicago:building_id                129830\n",
      "addr:street                        111769\n",
      "addr:housenumber                   111287\n",
      "addr:street:name                   109964\n",
      "                                    ...  \n",
      "public_transit                          1\n",
      "filming:location:movie:wikidata         1\n",
      "protection_title                        1\n",
      "brand:wikipedia                         1\n",
      "abandoned                               1\n",
      "Length: 448, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "research_audit(OSMFILE)    \n",
    "printTagList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are these?\n",
    "\n",
    "The above list has over 400 keys and all of them might not be useful.\n",
    "However, I've chosen some keys along with an example value that I find should be audited for \n",
    "consistency, accuracy, and uniformity.\n",
    "\n",
    "| Key           | Example Values |\n",
    "| ------------- |:-------------:|\n",
    "| addr:street   | South Kilpatrick Avenue, West Chicago Ave |\n",
    "| phone  | 312-226-0670, (312) 226-1988 |\n",
    "\n",
    "\n",
    "The listed fields above present some issues. For \"addr:street\" we have inconsistent street types such as Avenue and Ave. These will need to be formatted into a single street type. Also, \"phone\" should be formated to a single style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with street names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list to check against for inconsistant street types. These are the desired street types, non-abbreviated\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Access\"]\n",
    "\n",
    "#Regex to find street types gets last word in a string\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "def check_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_type(elem):\n",
    "    return ((elem.attrib['k'] == \"addr:street\"))\n",
    "\n",
    "# loop through and populate a dictionary containing non-expected street types\n",
    "def audit_research_street_type(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_type(tag):\n",
    "                    check_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    l = 10 if len(keys) > 10 else len(keys) \n",
    "    for k in keys[:l]:\n",
    "        v = d[k]\n",
    "        print((k, v) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1425', {'N Lake Shore Dr #1425'})\n",
      "('1850', {'E Madison St #1850'})\n",
      "('2105', {'North Michigan Avenue # 2105'})\n",
      "('400', {'South Michigan Avenue # 400'})\n",
      "('500', {'Delaware Pl #500'})\n",
      "('510', {'W Madison St #510'})\n",
      "('575', {'N LaSalle St, #575'})\n",
      "('Ave', {'West Chicago Ave'})\n",
      "('Blvd', {'West Jackson Blvd', 'W Jackson Blvd'})\n",
      "('Bouevard', {'West Garfield Bouevard'})\n"
     ]
    }
   ],
   "source": [
    "st_types = audit_research_street_type(OSMFILE)\n",
    "print_sorted_dict(st_types)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can bring some consistency to street names by converting all abbraviations to the full word even if only one instance of it used:\n",
    "\n",
    "* Blvd, Bouevard(typo found) -> Boulevard\n",
    "* Ave -> Avenue\n",
    "* Dr -> Drive\n",
    "* St, St. -> Street\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "found_street_changes = defaultdict(set)\n",
    "     \n",
    "# Map to convert abbreviated street type to its respective full street type\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Dr\" : \"Drive\",\n",
    "            \"Dr.\" : \"Drive\",\n",
    "            \"Blvd\" : \"Boulevard\",\n",
    "            \"Bouevard\" : \"Boulevard\",\n",
    "            \"Pl\" : \"Place\"\n",
    "            }\n",
    "# similar to last time but this time replace the street type and track this change in a dictionary\n",
    "def check_street_type(street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected and street_type in mapping.keys():\n",
    "            replaced = street_type_re.sub(mapping[street_type], street_name)\n",
    "            street_name = replaced\n",
    "            found_street_changes[street_type].add(street_name)\n",
    "    return street_name\n",
    "\n",
    "def audit_street_type(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_type(tag):\n",
    "                    check_street_type(tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ave', {'West Chicago Avenue'})\n",
      "('Blvd', {'W Jackson Boulevard', 'West Jackson Boulevard'})\n",
      "('Bouevard', {'West Garfield Boulevard'})\n",
      "('Dr', {'North Upper Wacker Drive'})\n",
      "('St', {'W 63rd Street', 'Adams Street', 'N Clark Street', 'N LaSalle Street', 'E Oak Street', 'W Lake Street', 'W 18th Street', 'S Dearborn Street'})\n",
      "('St.', {'W. Lake Street', 'W. Madison Street'})\n"
     ]
    }
   ],
   "source": [
    "audit_street_type(OSMFILE)\n",
    "print_sorted_dict(found_street_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with phone numbers\n",
    "\n",
    "Using the same technique we're going to replace all different phone number strings to only include the digits with no spaces. For example: 1234567891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# regex to find different formated phone numbers\n",
    "phone_format_reg = re.compile(r'\\+?1?\\s*\\(?-*\\.*(\\d{3})\\)?\\.*-*\\s*(\\d{3})\\.*-*\\s*(\\d{4})$')     \n",
    "found_phone_changes = defaultdict(set)\n",
    "\n",
    "# repalce all formated phone numbers with just numerical versions only\n",
    "def format_phone_num(phone):\n",
    "    m = phone_format_reg.search(phone)\n",
    "    if m:\n",
    "        numbers_list = re.findall('\\d+', phone)\n",
    "        if numbers_list[0] is \"1\":\n",
    "            numbers_list.pop(0)\n",
    "        elif numbers_list[0].startswith('1',0,1):\n",
    "            numbers_list[0] = numbers_list[0][:0] + numbers_list[0][(0+1):]\n",
    "        numbers = \"\".join(numbers_list)\n",
    "        found_phone_changes[m.group()].add(numbers)\n",
    "        phone = numbers\n",
    "    return phone\n",
    "\n",
    "def is_phone_num(elem):\n",
    "    return ((elem.attrib['k'] == \"phone\"))\n",
    "\n",
    "def audit_phone(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_phone_num(tag):\n",
    "                    format_phone_num(tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' 312-780-1314', {'3127801314'})\n",
      "('(312) 222-9899', {'3122229899'})\n",
      "('(312) 226-1988', {'3122261988'})\n",
      "('(312) 226-4017', {'3122264017'})\n",
      "('(312) 238-9650', {'3122389650'})\n",
      "('(312) 239-3603', {'3122393603'})\n",
      "('(312) 251-7009', {'3122517009'})\n",
      "('(312) 267-0571', {'3122670571'})\n",
      "('(312) 322-6777', {'3123226777'})\n",
      "('(312) 329-1000', {'3123291000'})\n"
     ]
    }
   ],
   "source": [
    "audit_phone(OSMFILE)\n",
    "print_sorted_dict(found_phone_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together and exporting to JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_colon = re.compile(r'^(\\b\\S+\\.?)*:(\\b\\S+\\.?)*$', re.IGNORECASE)\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def handle_address(elem, key, node):\n",
    "    value = elem.attrib['v']\n",
    "    if is_street_type(elem):\n",
    "        value = check_street_type(value)\n",
    "    add_dict(\"address\", key, value, node)\n",
    "\n",
    "def add_dict(dict_name, key, value, node):\n",
    "    if dict_name in node and type(node[dict_name]) is dict:\n",
    "        node[dict_name][key] = value\n",
    "    else:\n",
    "        node[dict_name] = {}\n",
    "        node[dict_name][key] = value\n",
    "    return node\n",
    "\n",
    "def handle_tag(elem, node):\n",
    "    if problemchars.search(elem.attrib['k']):\n",
    "        return node\n",
    "    elif (elem.attrib['k'] == \"phone\"):\n",
    "        node[\"phone\"] = format_phone_num(elem.attrib['v'])\n",
    "    elif (lower_colon.search(elem.attrib['k'])):\n",
    "        colon_split = elem.attrib['k'].split(':')\n",
    "        if colon_split[0] == 'addr':\n",
    "            handle_address(elem, colon_split[1], node)\n",
    "        else:\n",
    "            add_dict(colon_split[0], colon_split[1], elem.attrib['v'], node)\n",
    "    else:\n",
    "        node[elem.attrib['k']] = elem.attrib['v']\n",
    "    return node\n",
    "\n",
    "def handle_pos(value, node):\n",
    "    if (\"pos\" in node) :\n",
    "        node[\"pos\"].append(float(value))\n",
    "    else:\n",
    "        node[\"pos\"] = []\n",
    "        node[\"pos\"].append(float(value))\n",
    "\n",
    "def handle_elem(elem, node):\n",
    "    node[\"type\"] = elem.tag\n",
    "    for attr, value in elem.attrib.items():\n",
    "        if ( attr == \"lat\" or attr == \"lon\" ):\n",
    "            handle_pos(value, node)\n",
    "        elif attr in CREATED:\n",
    "            add_dict(\"created\", attr, value, node)\n",
    "        else:\n",
    "            node[attr] = value\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        handle_elem(element, node)\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            handle_tag(tag, node)\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"mongo_chicago.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished creating JSON file\n"
     ]
    }
   ],
   "source": [
    "process_map(OSMFILE, True)\n",
    "print(\"Finished creating JSON file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('59f92970d5022e753d78504d'),\n",
       " 'created': {'changeset': '8323836',\n",
       "  'timestamp': '2011-06-02T20:24:34Z',\n",
       "  'uid': '451048',\n",
       "  'user': 'bbmiller',\n",
       "  'version': '9'},\n",
       " 'id': '20216902',\n",
       " 'pos': [41.8895268, -87.6393324],\n",
       " 'source': 'PGS',\n",
       " 'type': 'node'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "client.database_names()\n",
    "db = client.local\n",
    "chi = db[\"mongo_chicago\"]\n",
    "chi.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Name        | Size           |\n",
    "| ------------- |:----------:|\n",
    "| chicago_city.osm| 312 MB |\n",
    "| mongo_chicago.json| 353 MB |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'db': 'local', 'collections': 2, 'views': 0, 'objects': 1441966, 'avgObjSize': 228.703004093023, 'dataSize': 329781956.0, 'storageSize': 91361280.0, 'numExtents': 0, 'indexes': 2, 'indexSize': 14282752.0, 'ok': 1.0}\n"
     ]
    }
   ],
   "source": [
    "## Info on the DB\n",
    "print(db.command(\"dbstats\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinct users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chi.find().distinct(\"created.user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206527"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi.find({\"type\":\"way\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235428"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi.find({\"type\":\"node\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of cafes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi.find({\"amenity\":\"cafe\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'burger', 'count': 78},\n",
       " {'_id': 'sandwich', 'count': 43},\n",
       " {'_id': 'coffee_shop', 'count': 36},\n",
       " {'_id': 'mexican', 'count': 29},\n",
       " {'_id': 'pizza', 'count': 26},\n",
       " {'_id': 'chicken', 'count': 17},\n",
       " {'_id': 'american', 'count': 16},\n",
       " {'_id': 'italian', 'count': 15},\n",
       " {'_id': 'chinese', 'count': 13},\n",
       " {'_id': 'japanese', 'count': 8}]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chi.aggregate([{\"$match\": {\n",
    "            \"cuisine\": { \"$exists\": True}\n",
    "        }},{\"$group\" : {\"_id\" : \"$cuisine\", \"count\" : {\"$sum\" : 1}}},\n",
    "    {\"$sort\" : {\"count\" : -1}}, {\"$limit\":10}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'parking', 'count': 1440},\n",
       " {'_id': 'place_of_worship', 'count': 611},\n",
       " {'_id': 'school', 'count': 411},\n",
       " {'_id': 'restaurant', 'count': 357},\n",
       " {'_id': 'fast_food', 'count': 206},\n",
       " {'_id': 'bicycle_rental', 'count': 178},\n",
       " {'_id': 'cafe', 'count': 138},\n",
       " {'_id': 'fuel', 'count': 124},\n",
       " {'_id': 'fountain', 'count': 86},\n",
       " {'_id': 'bank', 'count': 74}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chi.aggregate([{\"$match\": {\n",
    "            \"amenity\": { \"$exists\": True}\n",
    "        }},{\"$group\" : {\"_id\" : \"$amenity\", \"count\" : {\"$sum\" : 1}}},\n",
    "    {\"$sort\" : {\"count\" : -1}}, {\"$limit\":10}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Areas for Improvement\n",
    "### The Name Field:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An area to improve in this analysis is the handling of the names field.\n",
    "Note that there is variablity in terms of what users input in that field. The expected and most common is actually the name of a particular location like a park's name or store name. However sometimes we see that this field is used for intersections and address as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Ada's Famous Deli & Restaurant\",\n",
      " \"Pizano's Pizza & Pasta\",\n",
      " 'Michigan & Madison-Monroe',\n",
      " 'State & Madison',\n",
      " 'Midtown Kitchen & Bar',\n",
      " 'Solidarity Drive & Adler Planetarium',\n",
      " 'State & Monroe',\n",
      " 'J&M Tap',\n",
      " 'Lake Shore Dr & Ohio St',\n",
      " 'Bear & Bull']\n"
     ]
    }
   ],
   "source": [
    "#regex to find anything contiaining &. & because it is used to many intersection names\n",
    "contains_ampersand = re.compile(r'[&]')\n",
    "amp_list = list(chi.find({'name':contains_ampersand}).distinct(\"name\"))\n",
    "# don't want print the entire list since it's huge.\n",
    "pprint.pprint(amp_list[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363\n"
     ]
    }
   ],
   "source": [
    "## Note not all of these are intersections but a it looks like a majority of them are\n",
    "print(len(amp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Streeterville',\n",
      " '21st Street',\n",
      " '16th Street',\n",
      " '18th Street',\n",
      " 'Ash Street Mp 5.6',\n",
      " 'CP 54th Street',\n",
      " 'CP 59th Street',\n",
      " 'CP Lumber Street',\n",
      " 'Museum Campus / 11th Street',\n",
      " 'Van Buren Street']\n"
     ]
    }
   ],
   "source": [
    "## regex to find contianing the word street but not the character &\n",
    "contains_street = re.compile(r'^(?=.*street)(?!.*&).*',re.IGNORECASE)\n",
    "\n",
    "st_list = list(chi.find({'name':contains_street}).distinct(\"name\"))\n",
    "pprint.pprint(st_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n"
     ]
    }
   ],
   "source": [
    "## Note this is just for the word street, consider other common types like avenue and lane\n",
    "print(len(st_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could attempt something similar to what we did for addr:street field before. For intersections I think they could be better served as their own field, like the highway field. For street names they should be merged with the street names field. However, it wont be that simple since as mentioned before the name field is highly variable. Above I only matched for names containing an ampersand and then for names that contain the word street and not an ampersand. This is not very precise at all since there are names that are not intersections that contain ampersands like \"H&R Block\". So to do this would not be an easy feat using the methods above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another area for improving this analysis would be to add cross validation for these inputs from other data sources. The data provided from MapZen is user driven like wikipedia however unlike wikipedia there isn't an easy way to check the input's claim from sources listed.\n",
    "\n",
    "Along with this we can also cross validate certain inputs with another data source. A popular option for chicago is the city's data portal (https://data.cityofchicago.org/). So for example, the nodes detailing anything from the Chicago Transit Authority (CTA) can be validated against the data on this site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('59f92970d5022e753d785304'),\n",
      "  'alt_name': 'Chicago/Franklin',\n",
      "  'created': {'changeset': '51870343',\n",
      "              'timestamp': '2017-09-09T06:45:26Z',\n",
      "              'uid': '1237170',\n",
      "              'user': 'Zol87',\n",
      "              'version': '10'},\n",
      "  'id': '102715649',\n",
      "  'name': 'Chicago',\n",
      "  'operator': 'Chicago Transit Authority',\n",
      "  'platforms': '2',\n",
      "  'pos': [41.8962625, -87.6357112],\n",
      "  'railway': 'station',\n",
      "  'type': 'node'},\n",
      " {'_id': ObjectId('59f92970d5022e753d785608'),\n",
      "  'created': {'changeset': '51871051',\n",
      "              'timestamp': '2017-09-09T07:25:27Z',\n",
      "              'uid': '1237170',\n",
      "              'user': 'Zol87',\n",
      "              'version': '18'},\n",
      "  'id': '258026049',\n",
      "  'name': 'UIC-Halsted',\n",
      "  'operator': 'Chicago Transit Authority',\n",
      "  'platforms': '1',\n",
      "  'pos': [41.875474, -87.6496755],\n",
      "  'railway': 'station',\n",
      "  'station': 'subway',\n",
      "  'type': 'node',\n",
      "  'wheelchair': 'no'}]\n"
     ]
    }
   ],
   "source": [
    "contains_transit = re.compile(r'^(?=.*Chicago Transit Authority)(?!.*&).*',re.IGNORECASE)\n",
    "\n",
    "transit = list(chi.find({\"operator\":contains_transit}))\n",
    "pprint.pprint(transit[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CTA dataset link:\n",
    "https://data.cityofchicago.org/Transportation/CTA-List-of-CTA-Datasets/pnau-cf66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of this would be wonderful for adding confidence in the dataset. However, implementing this would be a challenge. One possible way is that we can query the second database when building the JSON file. The problem with that though is that would drastically increase the time to build the JSON file. Not only that but building out the query to the validation dataset would not be simple either, since there is a lot variation in certain fields like name. So we would have to be careful in building out the query."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
